{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e6f60b5-f935-4688-9150-72a6f5399fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.insert(1, \"../\")  \n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "from aif360.datasets import CompasDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "\n",
    "# Scalers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Utilities\n",
    "from aif360.utils.general_utils import compute_metrics\n",
    "from aif360.utils.classifier_metrics import ClassifierMetricUtils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Explainers\n",
    "from aif360.explainers import MetricTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36103ce4-463b-45e2-8887-10ef5a82a766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 5 rows removed from CompasDataset.\n"
     ]
    }
   ],
   "source": [
    "dataset_orig = CompasDataset(\n",
    "    protected_attribute_names=['sex'],\n",
    "    privileged_classes=[['Female']],\n",
    "    features_to_drop=['race', 'age']\n",
    ")\n",
    "\n",
    "dataset_orig_train, dataset_orig_val, dataset_orig_test = dataset_orig.split([0.5,0.8], shuffle=True)\n",
    "\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "scale_orig = StandardScaler()\n",
    "X_train = scale_orig.fit_transform(dataset_orig_train.features)\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "w_train = dataset_orig_train.instance_weights.ravel()\n",
    "\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train, \n",
    "         sample_weight=dataset_orig_train.instance_weights)\n",
    "y_train_pred = lmod.predict(X_train)\n",
    "\n",
    "# positive class index\n",
    "pos_ind = np.where(lmod.classes_ == dataset_orig_train.favorable_label)[0][0]\n",
    "\n",
    "dataset_orig_train_pred = dataset_orig_train.copy()\n",
    "dataset_orig_train_pred.labels = y_train_pred\n",
    "\n",
    "dataset_orig_valid_pred = dataset_orig_val.copy(deepcopy=True)\n",
    "X_valid = scale_orig.transform(dataset_orig_valid_pred.features)\n",
    "y_valid = dataset_orig_valid_pred.labels\n",
    "dataset_orig_valid_pred.scores = lmod.predict_proba(X_valid)[:,pos_ind].reshape(-1,1)\n",
    "\n",
    "dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "X_test = scale_orig.transform(dataset_orig_test_pred.features)\n",
    "y_test = dataset_orig_test_pred.labels\n",
    "dataset_orig_test_pred.scores = lmod.predict_proba(X_test)[:,pos_ind].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "981bffd2-f12c-4d3c-a109-f6627a9756b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 975.0, 'FP': 826.0, 'TN': 34.0, 'FN': 15.0}\n",
      "{'TP': 974.0, 'FP': 822.0, 'TN': 38.0, 'FN': 16.0}\n",
      "{'TP': 974.0, 'FP': 820.0, 'TN': 40.0, 'FN': 16.0}\n",
      "{'TP': 974.0, 'FP': 817.0, 'TN': 43.0, 'FN': 16.0}\n",
      "{'TP': 973.0, 'FP': 811.0, 'TN': 49.0, 'FN': 17.0}\n",
      "{'TP': 972.0, 'FP': 807.0, 'TN': 53.0, 'FN': 18.0}\n",
      "{'TP': 971.0, 'FP': 801.0, 'TN': 59.0, 'FN': 19.0}\n",
      "{'TP': 971.0, 'FP': 796.0, 'TN': 64.0, 'FN': 19.0}\n",
      "{'TP': 970.0, 'FP': 787.0, 'TN': 73.0, 'FN': 20.0}\n",
      "{'TP': 969.0, 'FP': 779.0, 'TN': 81.0, 'FN': 21.0}\n",
      "{'TP': 967.0, 'FP': 774.0, 'TN': 86.0, 'FN': 23.0}\n",
      "{'TP': 965.0, 'FP': 769.0, 'TN': 91.0, 'FN': 25.0}\n",
      "{'TP': 963.0, 'FP': 764.0, 'TN': 96.0, 'FN': 27.0}\n",
      "{'TP': 962.0, 'FP': 757.0, 'TN': 103.0, 'FN': 28.0}\n",
      "{'TP': 960.0, 'FP': 748.0, 'TN': 112.0, 'FN': 30.0}\n",
      "{'TP': 958.0, 'FP': 747.0, 'TN': 113.0, 'FN': 32.0}\n",
      "{'TP': 957.0, 'FP': 741.0, 'TN': 119.0, 'FN': 33.0}\n",
      "{'TP': 955.0, 'FP': 733.0, 'TN': 127.0, 'FN': 35.0}\n",
      "{'TP': 953.0, 'FP': 726.0, 'TN': 134.0, 'FN': 37.0}\n",
      "{'TP': 952.0, 'FP': 721.0, 'TN': 139.0, 'FN': 38.0}\n",
      "{'TP': 951.0, 'FP': 712.0, 'TN': 148.0, 'FN': 39.0}\n",
      "{'TP': 949.0, 'FP': 699.0, 'TN': 161.0, 'FN': 41.0}\n",
      "{'TP': 948.0, 'FP': 691.0, 'TN': 169.0, 'FN': 42.0}\n",
      "{'TP': 948.0, 'FP': 688.0, 'TN': 172.0, 'FN': 42.0}\n",
      "{'TP': 946.0, 'FP': 678.0, 'TN': 182.0, 'FN': 44.0}\n",
      "{'TP': 943.0, 'FP': 670.0, 'TN': 190.0, 'FN': 47.0}\n",
      "{'TP': 935.0, 'FP': 662.0, 'TN': 198.0, 'FN': 55.0}\n",
      "{'TP': 933.0, 'FP': 654.0, 'TN': 206.0, 'FN': 57.0}\n",
      "{'TP': 928.0, 'FP': 650.0, 'TN': 210.0, 'FN': 62.0}\n",
      "{'TP': 922.0, 'FP': 639.0, 'TN': 221.0, 'FN': 68.0}\n",
      "{'TP': 921.0, 'FP': 633.0, 'TN': 227.0, 'FN': 69.0}\n",
      "{'TP': 917.0, 'FP': 620.0, 'TN': 240.0, 'FN': 73.0}\n",
      "{'TP': 915.0, 'FP': 608.0, 'TN': 252.0, 'FN': 75.0}\n",
      "{'TP': 910.0, 'FP': 598.0, 'TN': 262.0, 'FN': 80.0}\n",
      "{'TP': 905.0, 'FP': 586.0, 'TN': 274.0, 'FN': 85.0}\n",
      "{'TP': 895.0, 'FP': 574.0, 'TN': 286.0, 'FN': 95.0}\n",
      "{'TP': 890.0, 'FP': 564.0, 'TN': 296.0, 'FN': 100.0}\n",
      "{'TP': 882.0, 'FP': 553.0, 'TN': 307.0, 'FN': 108.0}\n",
      "{'TP': 877.0, 'FP': 546.0, 'TN': 314.0, 'FN': 113.0}\n",
      "{'TP': 869.0, 'FP': 530.0, 'TN': 330.0, 'FN': 121.0}\n",
      "{'TP': 852.0, 'FP': 519.0, 'TN': 341.0, 'FN': 138.0}\n",
      "{'TP': 845.0, 'FP': 514.0, 'TN': 346.0, 'FN': 145.0}\n",
      "{'TP': 838.0, 'FP': 507.0, 'TN': 353.0, 'FN': 152.0}\n",
      "{'TP': 825.0, 'FP': 491.0, 'TN': 369.0, 'FN': 165.0}\n",
      "{'TP': 814.0, 'FP': 477.0, 'TN': 383.0, 'FN': 176.0}\n",
      "{'TP': 808.0, 'FP': 468.0, 'TN': 392.0, 'FN': 182.0}\n",
      "{'TP': 795.0, 'FP': 455.0, 'TN': 405.0, 'FN': 195.0}\n",
      "{'TP': 786.0, 'FP': 443.0, 'TN': 417.0, 'FN': 204.0}\n",
      "{'TP': 780.0, 'FP': 426.0, 'TN': 434.0, 'FN': 210.0}\n",
      "{'TP': 766.0, 'FP': 406.0, 'TN': 454.0, 'FN': 224.0}\n",
      "{'TP': 757.0, 'FP': 384.0, 'TN': 476.0, 'FN': 233.0}\n",
      "{'TP': 751.0, 'FP': 375.0, 'TN': 485.0, 'FN': 239.0}\n",
      "{'TP': 732.0, 'FP': 352.0, 'TN': 508.0, 'FN': 258.0}\n",
      "{'TP': 719.0, 'FP': 338.0, 'TN': 522.0, 'FN': 271.0}\n",
      "{'TP': 704.0, 'FP': 318.0, 'TN': 542.0, 'FN': 286.0}\n",
      "{'TP': 695.0, 'FP': 307.0, 'TN': 553.0, 'FN': 295.0}\n",
      "{'TP': 679.0, 'FP': 286.0, 'TN': 574.0, 'FN': 311.0}\n",
      "{'TP': 656.0, 'FP': 271.0, 'TN': 589.0, 'FN': 334.0}\n",
      "{'TP': 646.0, 'FP': 266.0, 'TN': 594.0, 'FN': 344.0}\n",
      "{'TP': 631.0, 'FP': 255.0, 'TN': 605.0, 'FN': 359.0}\n",
      "{'TP': 615.0, 'FP': 239.0, 'TN': 621.0, 'FN': 375.0}\n",
      "{'TP': 604.0, 'FP': 229.0, 'TN': 631.0, 'FN': 386.0}\n",
      "{'TP': 583.0, 'FP': 218.0, 'TN': 642.0, 'FN': 407.0}\n",
      "{'TP': 558.0, 'FP': 204.0, 'TN': 656.0, 'FN': 432.0}\n",
      "{'TP': 521.0, 'FP': 192.0, 'TN': 668.0, 'FN': 469.0}\n",
      "{'TP': 512.0, 'FP': 188.0, 'TN': 672.0, 'FN': 478.0}\n",
      "{'TP': 487.0, 'FP': 176.0, 'TN': 684.0, 'FN': 503.0}\n",
      "{'TP': 466.0, 'FP': 158.0, 'TN': 702.0, 'FN': 524.0}\n",
      "{'TP': 445.0, 'FP': 153.0, 'TN': 707.0, 'FN': 545.0}\n",
      "{'TP': 394.0, 'FP': 134.0, 'TN': 726.0, 'FN': 596.0}\n",
      "{'TP': 387.0, 'FP': 134.0, 'TN': 726.0, 'FN': 603.0}\n",
      "{'TP': 358.0, 'FP': 115.0, 'TN': 745.0, 'FN': 632.0}\n",
      "{'TP': 344.0, 'FP': 105.0, 'TN': 755.0, 'FN': 646.0}\n",
      "{'TP': 325.0, 'FP': 99.0, 'TN': 761.0, 'FN': 665.0}\n",
      "{'TP': 310.0, 'FP': 94.0, 'TN': 766.0, 'FN': 680.0}\n",
      "{'TP': 289.0, 'FP': 89.0, 'TN': 771.0, 'FN': 701.0}\n",
      "{'TP': 259.0, 'FP': 81.0, 'TN': 779.0, 'FN': 731.0}\n",
      "{'TP': 244.0, 'FP': 77.0, 'TN': 783.0, 'FN': 746.0}\n",
      "{'TP': 216.0, 'FP': 68.0, 'TN': 792.0, 'FN': 774.0}\n",
      "{'TP': 208.0, 'FP': 66.0, 'TN': 794.0, 'FN': 782.0}\n",
      "{'TP': 196.0, 'FP': 61.0, 'TN': 799.0, 'FN': 794.0}\n",
      "{'TP': 180.0, 'FP': 56.0, 'TN': 804.0, 'FN': 810.0}\n",
      "{'TP': 151.0, 'FP': 49.0, 'TN': 811.0, 'FN': 839.0}\n",
      "{'TP': 135.0, 'FP': 45.0, 'TN': 815.0, 'FN': 855.0}\n",
      "{'TP': 120.0, 'FP': 45.0, 'TN': 815.0, 'FN': 870.0}\n",
      "{'TP': 110.0, 'FP': 42.0, 'TN': 818.0, 'FN': 880.0}\n",
      "{'TP': 103.0, 'FP': 38.0, 'TN': 822.0, 'FN': 887.0}\n",
      "{'TP': 89.0, 'FP': 37.0, 'TN': 823.0, 'FN': 901.0}\n",
      "{'TP': 78.0, 'FP': 33.0, 'TN': 827.0, 'FN': 912.0}\n",
      "{'TP': 73.0, 'FP': 33.0, 'TN': 827.0, 'FN': 917.0}\n",
      "{'TP': 69.0, 'FP': 31.0, 'TN': 829.0, 'FN': 921.0}\n",
      "{'TP': 64.0, 'FP': 30.0, 'TN': 830.0, 'FN': 926.0}\n",
      "{'TP': 61.0, 'FP': 28.0, 'TN': 832.0, 'FN': 929.0}\n",
      "{'TP': 57.0, 'FP': 26.0, 'TN': 834.0, 'FN': 933.0}\n",
      "{'TP': 53.0, 'FP': 26.0, 'TN': 834.0, 'FN': 937.0}\n",
      "{'TP': 52.0, 'FP': 25.0, 'TN': 835.0, 'FN': 938.0}\n",
      "{'TP': 47.0, 'FP': 25.0, 'TN': 835.0, 'FN': 943.0}\n",
      "{'TP': 41.0, 'FP': 25.0, 'TN': 835.0, 'FN': 949.0}\n",
      "{'TP': 38.0, 'FP': 23.0, 'TN': 837.0, 'FN': 952.0}\n",
      "{'TP': 38.0, 'FP': 22.0, 'TN': 838.0, 'FN': 952.0}\n",
      "Best balanced accuracy (no reweighing) = 0.6767\n",
      "Optimal classification threshold (no reweighing) = 0.5643\n"
     ]
    }
   ],
   "source": [
    "num_thresh = 100\n",
    "ba_arr = np.zeros(num_thresh)\n",
    "class_thresh_arr = np.linspace(0.01, 0.99, num_thresh)\n",
    "for idx, class_thresh in enumerate(class_thresh_arr):\n",
    "    \n",
    "    fav_inds = dataset_orig_valid_pred.scores > class_thresh\n",
    "    dataset_orig_valid_pred.labels[fav_inds] = dataset_orig_valid_pred.favorable_label\n",
    "    dataset_orig_valid_pred.labels[~fav_inds] = dataset_orig_valid_pred.unfavorable_label\n",
    "    \n",
    "    classified_metric_orig_valid = ClassificationMetric(dataset_orig_val,\n",
    "                                             dataset_orig_valid_pred, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "    print(classified_metric_orig_valid.binary_confusion_matrix())\n",
    "    \n",
    "    ba_arr[idx] = 0.5*(classified_metric_orig_valid.true_positive_rate()\\\n",
    "                       +classified_metric_orig_valid.true_negative_rate())\n",
    "\n",
    "best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
    "best_class_thresh = class_thresh_arr[best_ind]\n",
    "\n",
    "print(\"Best balanced accuracy (no reweighing) = %.4f\" % np.max(ba_arr))\n",
    "print(\"Optimal classification threshold (no reweighing) = %.4f\" % best_class_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb912da5-c646-4703-a3ab-3d34fe02a93f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
